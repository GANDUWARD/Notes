# Deep Learning-Based Job Placement in Distributed Machine Learning Clusters With Heterogeneous Workloads


## 分布式训练策略：分布式训练策略在这篇文章中包含了以下工作：


## worker：负责前向传播和反向传播计算


## parameter server：负责模型参数更新

![wf](/论文/论文图片/Harmony%20workflow.png)

**离线训练**：通过深度强化学习神经网络模型来减少训练所需的样本量


**在线推理**：对每次新到达的作业用模型进行放置决策。


**模型更新**：定期对模型进行更新与训练

## Interference Aware Scheduler：**干扰感知调度器**，比市面上的YARN等弱于干扰感知调度器在如今分布式训练的场景中更为被需要




当今的**白盒方法**主要面向特定场景和执行，对于干扰源有数十种明确的靶向并且依赖于对模型的细致优化与启发式方法的相关阈值

因为任何预设策略和数学模型的方法都会存在**通用性问题**

面对如今的场景，我们可以采用**基于深度学习的神经网络模型的负载均衡器**，用基于海量经验数据的**黑盒方法**，来对分布式大模型实现负载均衡和任务分配策略，工作感知的动态空间探索，经验再现


1. **负载均衡（Load Balancing）**： 负载均衡旨在将**计算任务均匀地分配到集群中的各个节点**上，以避免某些节点过载，而其他节点闲置。​在机器学习集群中，负载均衡可以通过监控各节点的资源使用情况，动态调整任务分配策略，从而提高整体资源利用率和任务处理效率。​

2. **装箱（Bin Packing）**： 装箱问题源自将**物品尽可能高效地放入有限容量的容器中**的经典优化问题。​在作业调度中，装箱方法关注如何将多个具有不同资源需求的任务安排到有限的计算资源上，以最小化资源浪费。​这通常涉及到复杂的优化算法，旨在在满足任务需求的同时，最大化资源利用率。​

3. **独立（Standalone）**： 在某些情况下，某些任务可能需要**独占资源运行**，或者由于其特殊的资源需求和性能要求，不能与其他任务共享节点资源。​这种情况下，任务以独立模式运行，确保其性能和稳定性。

## DRL：深度强化学习，其训练方法包括演员-评论家算法，

**分配策略**会有这样的问题：行为空间在jobs种类数量以及worker还有参数服务器还有服务器中随着数量**指数级增长**：哪怕六个工作在基于3个workers加上参数服务器以及六个服务器有超过一亿种放置方式


**Harmony**：机器学习集群调度器。以批处理方式调度作业，时间被划分为小的调度间隔。Harmony**不假设**作业到达时间是**预先已知**的，并在每个间隔中**批量处理新到达的作业**。然后它**决定整个批次的作业放置**，即每个作业中的每个工作者和每个参数服务器应该在哪个服务器上运行（作为虚拟机或容器）。然后根据放置决策部署作业，并且Harmony运行这些作业直至完成，即每个作业的工作者和参数服务器的放置在整个训练过程中**不会改变**。因此，Harmony只在每个调度间隔中**调度新到达**的作业，根据当前的资源可用性和服务器上先前到达作业的现有放置情况来放置它们。根据我们与运营大型AI云的公司（例如，微软[50]和阿里巴巴[51]）的讨论，**带有资源规格说明且部署后不进行放置调整的作业提交是机器学习集群中的常态**，主要是由于两个原因：（1）停止训练作业然后重新开始需要修改机器学习框架和用户代码以恢复正确的训练状态（例如，已训练的周期和迭代次数、随机种子等）。（2）停止和重新开始训练作业会带来显著的开销，包括重新调度时间、容器重启、数据集重新加载、检查点重新加载等[52]。在实践中，对正在运行的作业进行**无重大开销的动态资源调整**是难以实现的。






**样本量不足问题**：即使是简单的DeepRM——仅有一个隐藏层的简单神经网络也要用20000个样本。要解决这个问题，就需要采用一个基于神经网络的奖励预测模型



## 状态空间

**输入状态序列s**:由（s1,s2...sn）组成sn个数表示当前并发的作业数。sn由(xn, rn, wn, pn, v, d
n, un)


**xn**:xn,  L维二进制向量，编码了由作业n训练的ML模型，其中L是集群中可以训练的最大模型数量（即所有时间点上训练作业的类型总数）。为了简化，每个向量xn是一个作业n的模型的一次性编码[39]。相同的ML模型，例如，具有相同架构和小批量大小的DNN，但可能具有不同的学习率和总训练周期数，使用相同的编码。例如，如果有3个模型总共，并且每个模型分别使用3个并发作业，那么x0 = [1, 0, 0]，x1 = [0, 1, 0]，x2 = [0, 0, 1]。还存在其他可能的编码方法，例如特征嵌入[53]，我们将探索更高效的编码方法作为未来的工作。

**rn**:2(1+K)维度向量，K是资源种类数，第一个值表示n号job请求worker个数，后面K个值代表每个worker的各种资源请求个数。最后1+K表示job所请求的参数服务器个数以及每个参数服务器各个资源请求个数


**wn**:整数表示worker的数量



**v**:，一个 M × K 矩阵，代表服务器上每种类型资源的可用量，其中 M 是物理服务器的数量。每个向量 vm，∀m = 1,...,M，代表服务器 m 上的可用资源。例如，一个有 8 个可用 CPU 核心和 2 个可用 GPU 的服务器被编码为 vm = [8, 2]。

**dn**:一个M*2的向量对jobn的所有服务器上的worker和参数服务器进行编码服务器m在其中位置2m-1表示worker数，2m表示参数服务器数量，全归约结构中，参数服务器为0，所以2m位置肯定是0



**un**： 一个整数，表示第n个作业是新到达的还是在之前的调度间隔中已经安排好的。例如，u0 = 0 和 u1 = 1 分别表示作业0已经在之前被安排过，而作业1是当前调度间隔中到达的新作业。





## 动作空间



















## MapReduce jobs：网络密集型
















## HPC jobs：缓存访问密集型

